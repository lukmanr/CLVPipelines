# Build and deploy CLV components and pipelines

steps:

# Build the image for custom build steps 
- name: 'gcr.io/cloud-builders/docker'
  args: ['build', '-t', 'kfp-builder', '.']
  dir: 'deploy/kfp-builder'

# Build the base image for lightweight components
- name: 'gcr.io/cloud-builders/docker' 
  args: ['build', '-t', 'gcr.io/$PROJECT_ID/$_BASE_IMAGE:$_TAG', '.'] 
  dir: 'pipelines/helper_components'

# Build the AutoML Tables components image
- name:  'gcr.io/cloud-builders/docker' 
  args: ['build', '-t', 'gcr.io/$PROJECT_ID/$_AUTOML_TABLES_IMAGE:$_TAG', '.'] 
  dir: 'components/automl_tables'

# Update component specifications
#- name: 'gcr.io/cloud-builders/gcloud'
- name: 'kfp-builder'
  args: 
  - '-c'
  - |
    SED_SCRIPT='s/\([[:blank:]]*image:[[:blank:]]*\).*/\1gcr\.io\/$PROJECT_ID\/$_AUTOML_TABLES_IMAGE:$_TAG/'
    ls */component.yaml | xargs sed -i $$SED_SCRIPT 
  dir: 'components/automl_tables/specs'

# Update pipeline settings
#- name: 'gcr.io/cloud-builders/gcloud'
- name: 'kfp-builder'
  args: 
  - '-c'
  - |
    SED_SCRIPT='s/\([[:blank:]]*lightweight_components_base_image:[[:blank:]]*\).*/\1gcr\.io\/$PROJECT_ID\/$_BASE_IMAGE:$_TAG/'
    sed -i $$SED_SCRIPT settings.yaml
    SED_SCRIPT='s/\([[:blank:]]*query_template_uri:[[:blank:]]*\).*/\1gs:\/\/$_BUCKET_NAME\/$_ARTIFACTS_FOLDER\/query_template.sql.jinja/'
    sed -i $$SED_SCRIPT settings.yaml
  dir: 'pipelines'

# Compile the pipelines 
- name: 'kfp-builder'
  args:
  - '-c'
  - |
    dsl-compile --py  train_pipeline.py --output ${_TRAIN_PIPELINE}.tar.gz --disable-type-check
    dsl-compile --py  batch_predict_pipeline.py --output ${_PREDICT_PIPELINE}.tar.gz --disable-type-check
  dir: 'pipelines'

# Copy build artifacts to GCS bucket
- name: 'gcr.io/cloud-builders/gsutil'
  entrypoint: 'bash'
  args:
  - '-c'
  - |
    gsutil cp *.tar.gz gs://$_BUCKET_NAME/$_PIPELINES_FOLDER
    gsutil cp artifacts/query_template.sql.jinja gs://$_BUCKET_NAME/$_ARTIFACTS_FOLDER/query_template.sql.jinja 
    gsutil cp gs://clv-datasets/transactions/* gs://$_BUCKET_NAME/$_SAMPLE_DATASET_FOLDER 
  dir: 'pipelines'

# Upload compiled pipelines to the KFP cluster
- name: 'gcr.io/cloud-builders/gcloud'
  args: ['container', 'clusters', 'get-credentials', '$_CLUSTER_NAME', '--zone', '$_ZONE']

- name: 'kfp-builder'
  args:
  - '-c'
  - |
    python kfp-cli.py upload_pipeline --pipeline_package_path=../pipelines/${_TRAIN_PIPELINE}.tar.gz --pipeline_name=${_TRAIN_PIPELINE}
    python kfp-cli.py upload_pipeline --pipeline_package_path=../pipelines/${_PREDICT_PIPELINE}.tar.gz --pipeline_name=${_PREDICT_PIPELINE}
  dir: 'run'

images: ['gcr.io/$PROJECT_ID/${_BASE_IMAGE}', 'gcr.io/$PROJECT_ID/${_AUTOML_TABLES_IMAGE}']

